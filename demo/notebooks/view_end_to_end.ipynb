{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T22:29:14.036696285Z",
     "start_time": "2023-12-11T22:29:13.951328055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50d4ff4de266472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T22:29:19.258539226Z",
     "start_time": "2023-12-11T22:29:14.036486614Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 23:38:39 WARN Utils: Your hostname, LTO-CWT060 resolves to a loopback address: 127.0.1.1; using 192.168.0.23 instead (on interface wlp0s20f3)\n",
      "23/12/11 23:38:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /home/chen/.ivy2/cache\n",
      "The jars for the packages stored in: /home/chen/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f380e891-7f98-4187-b97d-785db03bd097;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/chen/Documents/presentation-meetup-datascience/demo/.venv/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in local-m2-cache\n",
      "\tfound com.typesafe#config;1.4.1 in local-m2-cache\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in local-m2-cache\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in local-m2-cache\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in local-m2-cache\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in local-m2-cache\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in spark-list\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in local-m2-cache\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in spark-list\n",
      "\tfound org.postgresql#postgresql;42.6.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      ":: resolution report :: resolve 2538ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from local-m2-cache in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from local-m2-cache in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from local-m2-cache in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from spark-list in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from local-m2-cache in [default]\n",
      "\tcom.typesafe#config;1.4.1 from local-m2-cache in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from local-m2-cache in [default]\n",
      "\torg.postgresql#postgresql;42.6.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from spark-list in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   3   |   3   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f380e891-7f98-4187-b97d-785db03bd097\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/7ms)\n",
      "23/12/11 23:38:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/11 23:38:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/12/11 23:38:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[2]\")\n",
    "    .appName(\"demo\")\n",
    "    .config(\n",
    "        map={\n",
    "            \"spark.driver.memory\": \"2G\",\n",
    "            \"spark.jars.packages\": \"com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,org.postgresql:postgresql:42.6.0\",\n",
    "            \"spark.sql.extensions\": \"com.datastax.spark.connector.CassandraSparkExtensions\",\n",
    "            \"spark.sql.catalog.comwatt\": \"com.datastax.spark.connector.datasource.CassandraCatalog\",\n",
    "            \"spark.sql.catalog.comwatt.spark.cassandra.connection.compression\": \"LZ4\",\n",
    "            \"spark.sql.catalog.comwatt.spark.cassandra.connection.host\": \"localhost:9042\",\n",
    "        }\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19dc81e78a0b9893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T22:29:21.703310182Z",
     "start_time": "2023-12-11T22:29:19.260810229Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------+-------+---------+-------------------------+\n",
      "|device_uid|connected_object_uid                |site_id|type     |label                    |\n",
      "+----------+------------------------------------+-------+---------+-------------------------+\n",
      "|0         |05ed9851-5343-47d9-9417-99422184eb29|0      |chauffage|Mon chauffage maison     |\n",
      "|1         |0fd49130-1973-418f-b101-3682942654e0|1      |chauffage|Le chauffage c'est la vie|\n",
      "|2         |14766b2f-4d6f-4849-afdf-d74639ac67a4|2      |four     |pour faire du pain       |\n",
      "+----------+------------------------------------+-------+---------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from demo.adapters.postgres_reader import PostgresClient, PostgresReader\n",
    "\n",
    "pg_client = PostgresClient(\n",
    "    spark, \"jdbc:postgresql://localhost:5432/comwatt\", \"postgres\", \"demo_password\"\n",
    ")\n",
    "device_reader = PostgresReader(pg_client, \"devices\")\n",
    "device_reader().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e3c463ea405673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T22:29:23.063805311Z",
     "start_time": "2023-12-11T22:29:21.703753548Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------------------------+-------------------+----------+\n",
      "|site_id|time_bucket|connected_object_uid                |timestamp          |value     |\n",
      "+-------+-----------+------------------------------------+-------------------+----------+\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-12 01:00:00|93.01135  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-12 00:00:00|102.2616  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 23:00:00|85.77224  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 22:00:00|86.07031  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 21:00:00|96.67746  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 20:00:00|96.364456 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 19:00:00|103.131714|\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 18:00:00|103.00402 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 17:00:00|106.04816 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 16:00:00|93.30115  |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 15:00:00|104.07514 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 14:00:00|108.52952 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 13:00:00|95.860176 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 12:00:00|107.50579 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 11:00:00|103.017876|\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 10:00:00|123.67249 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 09:00:00|106.15052 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 08:00:00|89.1875   |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 07:00:00|115.13999 |\n",
      "|0      |202309     |05ed9851-5343-47d9-9417-99422184eb29|2023-09-11 06:00:00|94.90151  |\n",
      "+-------+-----------+------------------------------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from demo.adapters.cassandra_reader import CassandraClient, CassandraReader\n",
    "\n",
    "cass_client = CassandraClient(spark, \"comwatt.comwatt\")\n",
    "measures_reader = CassandraReader(cass_client, \"measures\")\n",
    "measures_reader().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66340158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [site_id#146, connected_object_uid#145, device_uid#144, type#147, label#148, time_bucket#135, timestamp#137, value#138]\n",
      "   +- SortMergeJoin [cast(site_id#146 as bigint), connected_object_uid#145], [site_id#134L, connected_object_uid#136], Inner\n",
      "      :- Sort [cast(site_id#146 as bigint) ASC NULLS FIRST, connected_object_uid#145 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(cast(site_id#146 as bigint), connected_object_uid#145, 200), ENSURE_REQUIREMENTS, [plan_id=65]\n",
      "      :     +- Scan JDBCRelation(devices) [numPartitions=1] [device_uid#144,connected_object_uid#145,site_id#146,type#147,label#148] PushedFilters: [*IsNotNull(site_id), *IsNotNull(connected_object_uid)], ReadSchema: struct<device_uid:int,connected_object_uid:string,site_id:int,type:string,label:string>\n",
      "      +- Sort [site_id#134L ASC NULLS FIRST, connected_object_uid#136 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(site_id#134L, connected_object_uid#136, 200), ENSURE_REQUIREMENTS, [plan_id=66]\n",
      "            +- Project [site_id#134L, time_bucket#135, connected_object_uid#136, timestamp#137, value#138]\n",
      "               +- Filter ((timestamp#137 >= 2023-09-11 00:00:00) AND (timestamp#137 < 2023-09-12 00:00:00))\n",
      "                  +- BatchScan measures[site_id#134L, time_bucket#135, connected_object_uid#136, timestamp#137, value#138] Cassandra Scan: comwatt.measures\n",
      " - Cassandra Filters: []\n",
      " - Requested Columns: [site_id,time_bucket,connected_object_uid,timestamp,value] RuntimeFilters: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from demo.get_measures_of_date_for_devices import get_measures_of_date_for_devices\n",
    "\n",
    "get_measures_of_date_for_devices(\"2023-09-11\", device_reader, measures_reader).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ed290cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922]\n",
      "+- BatchScan measures[site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922] Cassandra Scan: comwatt.measures\n",
      " - Cassandra Filters: [[\"timestamp\" < ?, 2023-09-12 00:00:00.0],[\"connected_object_uid\" = ?, 0fd49130-1973-418f-b101-3682942654e0],[\"timestamp\" >= ?, 2023-09-11 00:00:00.0],[\"site_id\" = ?, 1],[\"time_bucket\" = ?, 202309]]\n",
      " - Requested Columns: [site_id,time_bucket,connected_object_uid,timestamp,value] RuntimeFilters: []\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922]\n",
      "+- BatchScan measures[site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922] Cassandra Scan: comwatt.measures\n",
      " - Cassandra Filters: [[\"timestamp\" < ?, 2023-09-12 00:00:00.0],[\"timestamp\" >= ?, 2023-09-11 00:00:00.0],[\"connected_object_uid\" = ?, 14766b2f-4d6f-4849-afdf-d74639ac67a4],[\"site_id\" = ?, 2],[\"time_bucket\" = ?, 202309]]\n",
      " - Requested Columns: [site_id,time_bucket,connected_object_uid,timestamp,value] RuntimeFilters: []\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922]\n",
      "+- BatchScan measures[site_id#918L, time_bucket#919, connected_object_uid#920, timestamp#921, value#922] Cassandra Scan: comwatt.measures\n",
      " - Cassandra Filters: [[\"timestamp\" < ?, 2023-09-12 00:00:00.0],[\"connected_object_uid\" = ?, 05ed9851-5343-47d9-9417-99422184eb29],[\"timestamp\" >= ?, 2023-09-11 00:00:00.0],[\"site_id\" = ?, 0],[\"time_bucket\" = ?, 202309]]\n",
      " - Requested Columns: [site_id,time_bucket,connected_object_uid,timestamp,value] RuntimeFilters: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_device = device_reader()\n",
    "df_measure = measures_reader()\n",
    "device_by_site = (\n",
    "    df_device.groupBy(\"site_id\")\n",
    "    .agg(F.collect_list(\"connected_object_uid\").alias(\"uids\"))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "for row in device_by_site:\n",
    "    (\n",
    "        df_measure.filter(F.col(\"site_id\") == row.site_id)\n",
    "        .filter(F.col(\"time_bucket\") == \"202309\")\n",
    "        .filter(F.col(\"connected_object_uid\").isin(row.uids))\n",
    "        .filter(F.col(\"timestamp\") >= \"2023-09-11\")\n",
    "        .filter(F.col(\"timestamp\") < \"2023-09-12\")\n",
    "        .explain()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d684cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
