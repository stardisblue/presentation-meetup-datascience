{
	// Place your demo workspace snippets here. Each snippet is defined under a snippet name and has a scope, prefix, body and 
	// description. Add comma separated ids of the languages where the snippet is applicable in the scope field. If scope 
	// is left empty or omitted, the snippet gets applied to all languages. The prefix is what is 
	// used to trigger the snippet and the body will be expanded and inserted. Possible variables are: 
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. 
	// Placeholders with the same ids are connected.
	// Example:
	// "Print to console": {
	// 	"scope": "javascript,typescript",
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }
	"Define pyspark fixture": {
		"scope": "python",
		"prefix": "fixture:pyspark",
		"body": [
			"@pytest.fixture(scope=\"session\")",
			"def spark():",
			"    spark = (",
			"        SparkSession.builder.master(\"local[2]\")",
			"        .appName(\"demo\")",
			"        .config(\"spark.driver.memory\", \"2G\")",
			"        .getOrCreate()",
			"    )",
			"    yield spark",
			"",
			"    spark.stop()"
			""
		],
		"description": "Defines simple pyspark fixture"
	},
	"Define pyspark fixture with cassandra": {
		"scope": "python",
		"prefix": "fixture:pyspark-full",
		"body": [
			"@pytest.fixture(scope=\"session\")",
			"def spark():",
			"    spark = (",
			"        SparkSession.builder.master(\"local[2]\")",
			"        .appName(\"demo\")",
			"        .config(",
			"            map={",
			"                \"spark.driver.memory\": \"2G\",",
			"                \"spark.jars.packages\": \"com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,org.postgresql:postgresql:42.6.0\",",
			"                \"spark.sql.extensions\": \"com.datastax.spark.connector.CassandraSparkExtensions\",",
			"                \"spark.sql.catalog.comwatt\": \"com.datastax.spark.connector.datasource.CassandraCatalog\",",
			"                \"spark.sql.catalog.comwatt.spark.cassandra.connection.compression\": \"LZ4\",",
			"                \"spark.sql.catalog.comwatt.spark.cassandra.connection.host\": \"localhost:9042\",",
			"            }",
			"        )",
			"        .getOrCreate()",
			"    )",
			"    yield spark",
			"",
			"    spark.stop()",
			""
		],
		"description": "Defines full pyspark fixture"
	},
	"device parquet instance": {
		"scope": "python",
		"prefix": "instance:parquet_devices",
		"body": [
			"devices = LocalParquetReader(spark, \"data/devices.parquet\")",
			""
		],
		"description": "Setup devices local parquet reader"
	},
	"measures parquet instance": {
		"scope": "python",
		"prefix": "instance:parquet_measures",
		"body": [
			"measures = LocalParquetReader(spark, \"data/measures.parquet\")",
			""
		],
		"description": "Setup measures local parquet reader"
	},
	"device postgresql instance": {
		"scope": "python",
		"prefix": "instance:postgres_devices",
		"body": [
			"device_reader = PostgresReader(",
			"    PostgresClient(",
			"        spark,",
			"        \"jdbc:postgresql://localhost:5432/comwatt\",",
			"        \"postgres\",",
			"        \"demo_password\",",
			"    ),",
			"    \"devices\",",
			")",
			""
		],
		"description": "Setup devices postgres client reader"
	},
	"measures parquet instance": {
		"scope": "python",
		"prefix": "instance:cassandra_measures",
		"body": [
			"measures_reader = CassandraReader(",
			"    CassandraClient(spark, \"comwatt.comwatt\"), \"measures\"",
			")",
			""
		],
		"description": "Setup measures cassandra reader"
	},
	"assertEqualDataframes": {
		"scope": "python",
		"prefix": "assertDataFrameEqual",
		"body": [
			"assertDataFrameEqual(device_measures.dataframe, validation, order=[\"device_uid\", \"timestamp\"])",
			""
		],
		"description": "assertEqualDataframes"
	},

}